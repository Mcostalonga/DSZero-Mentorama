{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Michell Luiz Costalonga\n",
    "\n",
    "# Exercícios - Módulo 15\n",
    "<br><br>\n",
    "\n",
    "# Exercício: Sistemas de Recomendação\n",
    "\n",
    "<br>\n",
    "\n",
    "__Introdução: o objetivo deste exercício é discutirmos uma metodologia de avaliação de filtros colaborativos.__\n",
    "\n",
    "<br>\n",
    "\n",
    "Para isso, utilize a função getData() para carregar os dados: \n",
    "\n",
    "    - teremos avaliações que 367 usuários fizeram a respeito de 80 filmes. As notas variam entre 1, 2, 3, 4, e 5. \n",
    "    \n",
    "    - os valores NaN representam filmes que ainda não foram avaliados pelos usuários.\n",
    "\n",
    "Como __modelo__ para as recomendações, usaremos a __fatoração matricial.__ Use a classe MatrixFactorization() construída ao longo do módulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "    ratings = pd.read_csv('u.data', sep='\\t', names=r_cols,\n",
    "                          encoding='latin-1')\n",
    "    m_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\n",
    "    movies = pd.read_csv('u.item', sep='|', names=m_cols, usecols=range(5),\n",
    "                         encoding='latin-1')\n",
    "    movie_ratings = pd.merge(movies, ratings)\n",
    "    temp = movie_ratings[['movie_id', 'user_id', 'rating']].copy()\n",
    "    temp = temp.pivot_table(columns='movie_id', index='user_id', values='rating').copy()\n",
    "    temp.index = ['User_'+str(int(i)) for i in temp.index]\n",
    "    temp.columns = ['Filme_'+str(int(i)) for i in temp.columns]\n",
    "    qtd_cols = 80\n",
    "    R = temp.iloc[:, :qtd_cols]\n",
    "    l=[]\n",
    "    for i in range(1, R.shape[0]+1):\n",
    "        if R.iloc[i-1, ].isnull().sum() >= (qtd_cols - 10):\n",
    "            l.append(i)\n",
    "    R = R.drop([\"User_\"+str(r) for r in l])\n",
    "    R.index = ['User_'+str(int(i)) for i in range(R.shape[0])]\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class MatrixFactorization():\n",
    "    \n",
    "    def __init__(self, dataframe, K, steps, alpha, beta):\n",
    "        self.df = dataframe\n",
    "        self.K = K\n",
    "        self.steps = steps\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        \n",
    "    def fit(self):\n",
    "        t0 = time.time()\n",
    "        \n",
    "        R = self.df.values\n",
    "        N, M = R.shape\n",
    "        \n",
    "        #inicio aleatorio\n",
    "        P = np.random.rand(N,self.K)\n",
    "        Q = np.random.rand(self.K,M)\n",
    "        \n",
    "        lista_erro_step = []\n",
    "        \n",
    "        #loop\n",
    "        for step in range(self.steps):\n",
    "            \n",
    "            mse_total_step = 0\n",
    "            #varrendo todas as entradas da matriz R\n",
    "            for i in range(len(R)):\n",
    "                for j in range(len(R[i])):\n",
    "                    #validando se o valor associado está preenchido\n",
    "                    if R[i][j] > 0:\n",
    "\n",
    "                        #calculando o erro:\n",
    "                        eij = R[i][j] - np.dot(P[i,:],Q[:,j])\n",
    "                        mse_total_step += (eij)**2\n",
    "                        #alterando os valores\n",
    "                        for k in range(self.K):\n",
    "                            P[i][k] = P[i][k] + self.alpha * ( 2 * eij * Q[k][j] - self.beta * P[i][k])\n",
    "                            Q[k][j] = Q[k][j] + self.alpha * ( 2 * eij * P[i][k] - self.beta * Q[k][j])\n",
    "                            \n",
    "            lista_erro_step.append(mse_total_step)\n",
    "            \n",
    "        self.P = P\n",
    "        self.Q = Q\n",
    "        self.lista_erro_step = lista_erro_step\n",
    "        t1 = time.time()\n",
    "        print(\"Fatoração concluída. Tempo aproximado:\", int(t1-t0), 'segundos.')\n",
    "        \n",
    "    def predict(self):\n",
    "        return self.P.dot(self.Q)\n",
    "    \n",
    "    def print_MSE_steps(self):\n",
    "        plt.figure(figsize=[15,6])\n",
    "        plt.title(\"Custo total por Step\", fontsize = 16, fontweight = 'bold')\n",
    "        plt.xlabel(\"Step\", fontsize = 14, fontweight = 'bold')\n",
    "        plt.ylabel(\"Erro\", fontsize = 14, fontweight = 'bold')\n",
    "        plt.plot(range(1, 1+self.steps), self.lista_erro_step, c = 'blue', lw = 2)\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "Tradicionalmente, para avaliarmos a performance de algoritmos de machine learning, fazemos a divisão dos dados em treino/teste; os dados de teste são utilizados no modelo final, apenas para validar que o mesmo não está sofrendo overfitting e está generalizando bem.\n",
    "\n",
    "No contexto dos filtros colaborativos, tal divisão dos dados não fará sentido: os métodos discutidos (de filtragem colaborativa) usam as informações de interação dos usuários com itens para \"preencher os valores faltantes\" da matriz de interação. Esse preenchimento é justamente a recomendação!\n",
    "\n",
    "<br>\n",
    "\n",
    "No entanto, podemos aplicar uma __metodologia que \"simula\" dados de treino/teste.__ \n",
    "\n",
    "Essencialmente, essa metodologia consiste de criar uma base de treino em que retiramos algumas interações dos usuários. Dessa forma, os modelos irão aprender os padrões dos dados sem terem acesso a toda informação.\n",
    "\n",
    "Nos dados de teste, usaremos essas interações retiradas em treino para avaliar os resultados.\n",
    "\n",
    "<br>\n",
    "\n",
    "__Considere o exemplo:__\n",
    "\n",
    "Vamos carregar, novamente, o dataset que usamos ao longo do módulo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDF():\n",
    "    dic__ = {\"User_1\":[np.nan, np.nan, np.nan, 1, 7, 2, 3, 8],\n",
    "         \"User_2\":[9,10,2,2,6,5,3,8],\n",
    "         \"User_3\":[4, 7, 9, 6,6,10,10,2],\n",
    "         \"User_4\":[np.nan, 7, 9, 5, 5, 10, 9, 1],\n",
    "         \"User_5\":[7.0,6.0,3.0,8.0,3,4.0,3.0, 2],\n",
    "         \"User_6\":[np.nan, np.nan, 9, 9,6,8,9,np.nan],\n",
    "         \"User_7\":[3,5,4,4,3,3,9,np.nan],\n",
    "         \"User_8\":[10,10,10,10,2,2,2,2],\n",
    "         \"User_9\":[9,9,np.nan,8,3,3,1,np.nan],\n",
    "         \"User_10\":[9,8,10,9,3,4,2,1],\n",
    "         \"User_11\":[4,4,3,3,9,9,8,10],\n",
    "         \"User_12\":[2,2,4,1,8,10,10,9],\n",
    "         \"User_13\":[1,4,1,3,7,10,7,8],\n",
    "         \"User_14\":[3,3,2,1,1,10, np.nan,10],\n",
    "         \"User_15\":[9,9,8,10,4,2,np.nan,1]\n",
    "        }\n",
    "    df = pd.DataFrame(dic__).T\n",
    "    df.columns = ['Filme_'+str(int(i+1)) for i in range(8)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filme_1</th>\n",
       "      <th>Filme_2</th>\n",
       "      <th>Filme_3</th>\n",
       "      <th>Filme_4</th>\n",
       "      <th>Filme_5</th>\n",
       "      <th>Filme_6</th>\n",
       "      <th>Filme_7</th>\n",
       "      <th>Filme_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_5</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_10</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_11</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_14</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_15</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Filme_1  Filme_2  Filme_3  Filme_4  Filme_5  Filme_6  Filme_7  \\\n",
       "User_1       NaN      NaN      NaN      1.0      7.0      2.0      3.0   \n",
       "User_2       9.0     10.0      2.0      2.0      6.0      5.0      3.0   \n",
       "User_3       4.0      7.0      9.0      6.0      6.0     10.0     10.0   \n",
       "User_4       NaN      7.0      9.0      5.0      5.0     10.0      9.0   \n",
       "User_5       7.0      6.0      3.0      8.0      3.0      4.0      3.0   \n",
       "User_6       NaN      NaN      9.0      9.0      6.0      8.0      9.0   \n",
       "User_7       3.0      5.0      4.0      4.0      3.0      3.0      9.0   \n",
       "User_8      10.0     10.0     10.0     10.0      2.0      2.0      2.0   \n",
       "User_9       9.0      9.0      NaN      8.0      3.0      3.0      1.0   \n",
       "User_10      9.0      8.0     10.0      9.0      3.0      4.0      2.0   \n",
       "User_11      4.0      4.0      3.0      3.0      9.0      9.0      8.0   \n",
       "User_12      2.0      2.0      4.0      1.0      8.0     10.0     10.0   \n",
       "User_13      1.0      4.0      1.0      3.0      7.0     10.0      7.0   \n",
       "User_14      3.0      3.0      2.0      1.0      1.0     10.0      NaN   \n",
       "User_15      9.0      9.0      8.0     10.0      4.0      2.0      NaN   \n",
       "\n",
       "         Filme_8  \n",
       "User_1       8.0  \n",
       "User_2       8.0  \n",
       "User_3       2.0  \n",
       "User_4       1.0  \n",
       "User_5       2.0  \n",
       "User_6       NaN  \n",
       "User_7       NaN  \n",
       "User_8       2.0  \n",
       "User_9       NaN  \n",
       "User_10      1.0  \n",
       "User_11     10.0  \n",
       "User_12      9.0  \n",
       "User_13      8.0  \n",
       "User_14     10.0  \n",
       "User_15      1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = getDF()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Abaixo, criamos o array \"ratings\", que consiste de nossa matriz de interação usuário/item. No entanto, fizemos um completamento com \"0\" nos dados faltantes. Dessa forma, o rating = 0 significa que o usuário não avaliou o filme em questão.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  7.,  2.,  3.,  8.],\n",
       "       [ 9., 10.,  2.,  2.,  6.,  5.,  3.,  8.],\n",
       "       [ 4.,  7.,  9.,  6.,  6., 10., 10.,  2.],\n",
       "       [ 0.,  7.,  9.,  5.,  5., 10.,  9.,  1.],\n",
       "       [ 7.,  6.,  3.,  8.,  3.,  4.,  3.,  2.],\n",
       "       [ 0.,  0.,  9.,  9.,  6.,  8.,  9.,  0.],\n",
       "       [ 3.,  5.,  4.,  4.,  3.,  3.,  9.,  0.],\n",
       "       [10., 10., 10., 10.,  2.,  2.,  2.,  2.],\n",
       "       [ 9.,  9.,  0.,  8.,  3.,  3.,  1.,  0.],\n",
       "       [ 9.,  8., 10.,  9.,  3.,  4.,  2.,  1.],\n",
       "       [ 4.,  4.,  3.,  3.,  9.,  9.,  8., 10.],\n",
       "       [ 2.,  2.,  4.,  1.,  8., 10., 10.,  9.],\n",
       "       [ 1.,  4.,  1.,  3.,  7., 10.,  7.,  8.],\n",
       "       [ 3.,  3.,  2.,  1.,  1., 10.,  0., 10.],\n",
       "       [ 9.,  9.,  8., 10.,  4.,  2.,  0.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = df.fillna(0).values\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Na sequência, apresentamos a função que faz a divisão dos dados em treino e teste.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings, qtd):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], \n",
    "                                        size=qtd, \n",
    "                                        replace=False)\n",
    "        train[user, test_ratings] = 0.\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "        \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings, qtd = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "__Vamos comparar os dados de treino e teste com os dados originais:__\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  7.,  2.,  3.,  8.],\n",
       "       [ 9., 10.,  2.,  2.,  6.,  5.,  3.,  8.],\n",
       "       [ 4.,  7.,  9.,  6.,  6., 10., 10.,  2.],\n",
       "       [ 0.,  7.,  9.,  5.,  5., 10.,  9.,  1.],\n",
       "       [ 7.,  6.,  3.,  8.,  3.,  4.,  3.,  2.],\n",
       "       [ 0.,  0.,  9.,  9.,  6.,  8.,  9.,  0.],\n",
       "       [ 3.,  5.,  4.,  4.,  3.,  3.,  9.,  0.],\n",
       "       [10., 10., 10., 10.,  2.,  2.,  2.,  2.],\n",
       "       [ 9.,  9.,  0.,  8.,  3.,  3.,  1.,  0.],\n",
       "       [ 9.,  8., 10.,  9.,  3.,  4.,  2.,  1.],\n",
       "       [ 4.,  4.,  3.,  3.,  9.,  9.,  8., 10.],\n",
       "       [ 2.,  2.,  4.,  1.,  8., 10., 10.,  9.],\n",
       "       [ 1.,  4.,  1.,  3.,  7., 10.,  7.,  8.],\n",
       "       [ 3.,  3.,  2.,  1.,  1., 10.,  0., 10.],\n",
       "       [ 9.,  9.,  8., 10.,  4.,  2.,  0.,  1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matriz de interação - original;\n",
    "\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  7.,  2.,  3.,  0.],\n",
       "       [ 9.,  0.,  2.,  2.,  0.,  5.,  3.,  8.],\n",
       "       [ 4.,  0.,  9.,  6.,  6., 10.,  0.,  2.],\n",
       "       [ 0.,  7.,  0.,  5.,  5.,  0.,  9.,  1.],\n",
       "       [ 7.,  6.,  3.,  8.,  3.,  4.,  0.,  0.],\n",
       "       [ 0.,  0.,  9.,  0.,  6.,  0.,  9.,  0.],\n",
       "       [ 3.,  5.,  4.,  4.,  3.,  0.,  0.,  0.],\n",
       "       [10.,  0., 10.,  0.,  2.,  2.,  2.,  2.],\n",
       "       [ 9.,  9.,  0.,  0.,  0.,  3.,  1.,  0.],\n",
       "       [ 9.,  8.,  0.,  0.,  3.,  4.,  2.,  1.],\n",
       "       [ 4.,  4.,  3.,  3.,  0.,  9.,  0., 10.],\n",
       "       [ 0.,  2.,  4.,  1.,  8.,  0., 10.,  9.],\n",
       "       [ 0.,  4.,  1.,  3.,  7., 10.,  7.,  0.],\n",
       "       [ 3.,  3.,  2.,  0.,  0., 10.,  0., 10.],\n",
       "       [ 9.,  0.,  8.,  0.,  4.,  2.,  0.,  1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dados de treino;\n",
    "#observe que, para cada usuário (ou seja, para cada linha) 3 notas foram retiradas!! \n",
    "#ou seja, foram substituida por 0.\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  8.],\n",
       "       [ 0., 10.,  0.,  0.,  6.,  0.,  0.,  0.],\n",
       "       [ 0.,  7.,  0.,  0.,  0.,  0., 10.,  0.],\n",
       "       [ 0.,  0.,  9.,  0.,  0., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  3.,  2.],\n",
       "       [ 0.,  0.,  0.,  9.,  0.,  8.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  3.,  9.,  0.],\n",
       "       [ 0., 10.,  0., 10.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  8.,  3.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., 10.,  9.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  9.,  0.,  8.,  0.],\n",
       "       [ 2.,  0.,  0.,  0.,  0., 10.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  8.],\n",
       "       [ 0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  9.,  0., 10.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dados de teste;\n",
    "#observe que exatamente as notas que foram retiradas de treino são colocadas nessa matriz de teste!!\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Na prática, usaremos os dados de treino para treinar e escolher os modelos.\n",
    "\n",
    "Neste caso, podemos, inclusive, fazer a divisão em treino/validação/teste:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(train, qtd = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  3.,  0.],\n",
       "       [ 9.,  0.,  2.,  2.,  0.,  0.,  3.,  0.],\n",
       "       [ 4.,  0.,  0.,  6.,  6.,  0.,  0.,  2.],\n",
       "       [ 0.,  7.,  0.,  5.,  0.,  0.,  9.,  0.],\n",
       "       [ 7.,  6.,  3.,  0.,  3.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  9.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 3.,  0.,  4.,  0.,  3.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., 10.,  0.,  0.,  2.,  2.,  2.],\n",
       "       [ 0.,  9.,  0.,  0.,  0.,  3.,  0.,  0.],\n",
       "       [ 9.,  0.,  0.,  0.,  3.,  4.,  0.,  1.],\n",
       "       [ 0.,  0.,  3.,  3.,  0.,  9.,  0., 10.],\n",
       "       [ 0.,  2.,  4.,  0.,  8.,  0.,  0.,  9.],\n",
       "       [ 0.,  4.,  1.,  0.,  7., 10.,  0.,  0.],\n",
       "       [ 0.,  3.,  2.,  0.,  0.,  0.,  0., 10.],\n",
       "       [ 0.,  0.,  8.,  0.,  0.,  2.,  0.,  1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  7.,  2.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  5.,  0.,  8.],\n",
       "       [ 0.,  0.,  9.,  0.,  0., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  5.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  8.,  0.,  4.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  6.,  0.,  9.,  0.],\n",
       "       [ 0.,  5.,  0.,  4.,  0.,  0.,  0.,  0.],\n",
       "       [10.,  0.,  0.,  0.,  2.,  0.,  0.,  0.],\n",
       "       [ 9.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  8.,  0.,  0.,  0.,  0.,  2.,  0.],\n",
       "       [ 4.,  4.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0., 10.,  0.],\n",
       "       [ 0.,  0.,  0.,  3.,  0.,  0.,  7.,  0.],\n",
       "       [ 3.,  0.,  0.,  0.,  0., 10.,  0.,  0.],\n",
       "       [ 9.,  0.,  0.,  0.,  4.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  8.],\n",
       "       [ 0., 10.,  0.,  0.,  6.,  0.,  0.,  0.],\n",
       "       [ 0.,  7.,  0.,  0.,  0.,  0., 10.,  0.],\n",
       "       [ 0.,  0.,  9.,  0.,  0., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  3.,  2.],\n",
       "       [ 0.,  0.,  0.,  9.,  0.,  8.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  3.,  9.,  0.],\n",
       "       [ 0., 10.,  0., 10.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  8.,  3.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., 10.,  9.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  9.,  0.,  8.,  0.],\n",
       "       [ 2.,  0.,  0.,  0.,  0., 10.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  8.],\n",
       "       [ 0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  9.,  0., 10.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Observe que, se \"juntamos\" os dados das 3 tabelas acima, retornamos com os dados originais:\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  7.,  2.,  3.,  8.],\n",
       "       [ 9., 10.,  2.,  2.,  6.,  5.,  3.,  8.],\n",
       "       [ 4.,  7.,  9.,  6.,  6., 10., 10.,  2.],\n",
       "       [ 0.,  7.,  9.,  5.,  5., 10.,  9.,  1.],\n",
       "       [ 7.,  6.,  3.,  8.,  3.,  4.,  3.,  2.],\n",
       "       [ 0.,  0.,  9.,  9.,  6.,  8.,  9.,  0.],\n",
       "       [ 3.,  5.,  4.,  4.,  3.,  3.,  9.,  0.],\n",
       "       [10., 10., 10., 10.,  2.,  2.,  2.,  2.],\n",
       "       [ 9.,  9.,  0.,  8.,  3.,  3.,  1.,  0.],\n",
       "       [ 9.,  8., 10.,  9.,  3.,  4.,  2.,  1.],\n",
       "       [ 4.,  4.,  3.,  3.,  9.,  9.,  8., 10.],\n",
       "       [ 2.,  2.,  4.,  1.,  8., 10., 10.,  9.],\n",
       "       [ 1.,  4.,  1.,  3.,  7., 10.,  7.,  8.],\n",
       "       [ 3.,  3.,  2.,  1.,  1., 10.,  0., 10.],\n",
       "       [ 9.,  9.,  8., 10.,  4.,  2.,  0.,  1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train + val + test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train + val + test) == ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Ou seja, com a metodologia acima, temos uma \"divisão\" dos dados em treino/validação/teste!\n",
    "\n",
    "\n",
    "Desta forma, podemos usar a metologia padrão de avaliação dos modelos:\n",
    "    \n",
    "    - Fitamos os modelos nos dados de treino;\n",
    "    \n",
    "    - Avaliamos os modelos nos dados de validação;\n",
    "    \n",
    "    - Escolhemos o modelo final, a partir dos resultados de validação;\n",
    "    \n",
    "    - Avaliamos o modelo final nos dados de teste.\n",
    "    \n",
    "    \n",
    "<br>\n",
    "\n",
    "\n",
    "__Ponto de atenção:__\n",
    "\n",
    "Ao calcularmos as métricas de performance, apenas os valores não nulos dos dados de validação/teste devem ser usados.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Vejamos um exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fat = MatrixFactorization(dataframe = pd.DataFrame(train, columns = df.columns, index = df.index), \n",
    "                          K = 5, steps = 5000, alpha = 0.0001, beta = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatoração concluída. Tempo aproximado: 4 segundos.\n"
     ]
    }
   ],
   "source": [
    "fat.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filme_1</th>\n",
       "      <th>Filme_2</th>\n",
       "      <th>Filme_3</th>\n",
       "      <th>Filme_4</th>\n",
       "      <th>Filme_5</th>\n",
       "      <th>Filme_6</th>\n",
       "      <th>Filme_7</th>\n",
       "      <th>Filme_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User_1</th>\n",
       "      <td>4.53</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.93</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.19</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2.92</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_2</th>\n",
       "      <td>8.62</td>\n",
       "      <td>5.71</td>\n",
       "      <td>2.23</td>\n",
       "      <td>1.82</td>\n",
       "      <td>3.34</td>\n",
       "      <td>5.90</td>\n",
       "      <td>3.12</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_3</th>\n",
       "      <td>3.99</td>\n",
       "      <td>3.01</td>\n",
       "      <td>7.71</td>\n",
       "      <td>5.70</td>\n",
       "      <td>5.67</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_4</th>\n",
       "      <td>10.25</td>\n",
       "      <td>6.91</td>\n",
       "      <td>5.48</td>\n",
       "      <td>4.92</td>\n",
       "      <td>9.51</td>\n",
       "      <td>9.36</td>\n",
       "      <td>8.64</td>\n",
       "      <td>10.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_5</th>\n",
       "      <td>6.97</td>\n",
       "      <td>5.71</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_6</th>\n",
       "      <td>8.39</td>\n",
       "      <td>6.70</td>\n",
       "      <td>8.84</td>\n",
       "      <td>6.40</td>\n",
       "      <td>7.31</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.56</td>\n",
       "      <td>4.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_7</th>\n",
       "      <td>2.98</td>\n",
       "      <td>2.81</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_8</th>\n",
       "      <td>7.50</td>\n",
       "      <td>6.23</td>\n",
       "      <td>9.50</td>\n",
       "      <td>6.49</td>\n",
       "      <td>5.59</td>\n",
       "      <td>2.11</td>\n",
       "      <td>2.18</td>\n",
       "      <td>1.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_9</th>\n",
       "      <td>8.95</td>\n",
       "      <td>8.70</td>\n",
       "      <td>7.25</td>\n",
       "      <td>4.41</td>\n",
       "      <td>4.79</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_10</th>\n",
       "      <td>8.71</td>\n",
       "      <td>6.39</td>\n",
       "      <td>5.53</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.01</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_11</th>\n",
       "      <td>8.97</td>\n",
       "      <td>5.22</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.18</td>\n",
       "      <td>7.39</td>\n",
       "      <td>8.84</td>\n",
       "      <td>7.18</td>\n",
       "      <td>9.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_12</th>\n",
       "      <td>5.19</td>\n",
       "      <td>2.15</td>\n",
       "      <td>3.90</td>\n",
       "      <td>4.24</td>\n",
       "      <td>7.84</td>\n",
       "      <td>6.50</td>\n",
       "      <td>6.60</td>\n",
       "      <td>8.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_13</th>\n",
       "      <td>8.24</td>\n",
       "      <td>3.97</td>\n",
       "      <td>1.15</td>\n",
       "      <td>2.19</td>\n",
       "      <td>6.80</td>\n",
       "      <td>9.66</td>\n",
       "      <td>6.99</td>\n",
       "      <td>9.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_14</th>\n",
       "      <td>7.04</td>\n",
       "      <td>2.98</td>\n",
       "      <td>2.03</td>\n",
       "      <td>3.02</td>\n",
       "      <td>7.08</td>\n",
       "      <td>8.10</td>\n",
       "      <td>6.69</td>\n",
       "      <td>9.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_15</th>\n",
       "      <td>5.76</td>\n",
       "      <td>4.81</td>\n",
       "      <td>7.69</td>\n",
       "      <td>5.21</td>\n",
       "      <td>4.59</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Filme_1  Filme_2  Filme_3  Filme_4  Filme_5  Filme_6  Filme_7  \\\n",
       "User_1      4.53     3.00     3.93     3.19     4.19     3.08     2.92   \n",
       "User_2      8.62     5.71     2.23     1.82     3.34     5.90     3.12   \n",
       "User_3      3.99     3.01     7.71     5.70     5.67     1.77     2.63   \n",
       "User_4     10.25     6.91     5.48     4.92     9.51     9.36     8.64   \n",
       "User_5      6.97     5.71     3.04     1.95     2.98     3.88     2.70   \n",
       "User_6      8.39     6.70     8.84     6.40     7.31     4.25     4.56   \n",
       "User_7      2.98     2.81     3.88     2.67     2.98     1.21     1.86   \n",
       "User_8      7.50     6.23     9.50     6.49     5.59     2.11     2.18   \n",
       "User_9      8.95     8.70     7.25     4.41     4.79     3.07     3.37   \n",
       "User_10     8.71     6.39     5.53     3.61     3.01     3.80     1.14   \n",
       "User_11     8.97     5.22     2.83     3.18     7.39     8.84     7.18   \n",
       "User_12     5.19     2.15     3.90     4.24     7.84     6.50     6.60   \n",
       "User_13     8.24     3.97     1.15     2.19     6.80     9.66     6.99   \n",
       "User_14     7.04     2.98     2.03     3.02     7.08     8.10     6.69   \n",
       "User_15     5.76     4.81     7.69     5.21     4.59     1.94     1.79   \n",
       "\n",
       "         Filme_8  \n",
       "User_1      3.68  \n",
       "User_2      4.59  \n",
       "User_3      2.25  \n",
       "User_4     10.64  \n",
       "User_5      3.15  \n",
       "User_6      4.81  \n",
       "User_7      1.67  \n",
       "User_8      1.76  \n",
       "User_9      2.97  \n",
       "User_10     1.27  \n",
       "User_11     9.71  \n",
       "User_12     8.74  \n",
       "User_13     9.56  \n",
       "User_14     9.71  \n",
       "User_15     1.04  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predição usando apenas os dados de treino!!\n",
    "\n",
    "pd.DataFrame(fat.predict(), columns = df.columns, index = df.index).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Veja que a matriz resultante __não é esparsa!__\n",
    "\n",
    "Dessa forma, como sabemos, podemos utilizá-la para as recomendações.\n",
    "\n",
    "Como __nosso objetivo no exercício é avaliar performance__, podemos __comparar__ os resultados dessa matriz resultante com os valores dos dados de validação!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filme_1</th>\n",
       "      <th>Filme_2</th>\n",
       "      <th>Filme_3</th>\n",
       "      <th>Filme_4</th>\n",
       "      <th>Filme_5</th>\n",
       "      <th>Filme_6</th>\n",
       "      <th>Filme_7</th>\n",
       "      <th>Filme_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_11</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_14</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_15</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Filme_1  Filme_2  Filme_3  Filme_4  Filme_5  Filme_6  Filme_7  \\\n",
       "User_1       0.0      0.0      0.0      0.0      7.0      2.0      0.0   \n",
       "User_2       0.0      0.0      0.0      0.0      0.0      5.0      0.0   \n",
       "User_3       0.0      0.0      9.0      0.0      0.0     10.0      0.0   \n",
       "User_4       0.0      0.0      0.0      0.0      5.0      0.0      0.0   \n",
       "User_5       0.0      0.0      0.0      8.0      0.0      4.0      0.0   \n",
       "User_6       0.0      0.0      0.0      0.0      6.0      0.0      9.0   \n",
       "User_7       0.0      5.0      0.0      4.0      0.0      0.0      0.0   \n",
       "User_8      10.0      0.0      0.0      0.0      2.0      0.0      0.0   \n",
       "User_9       9.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "User_10      0.0      8.0      0.0      0.0      0.0      0.0      2.0   \n",
       "User_11      4.0      4.0      0.0      0.0      0.0      0.0      0.0   \n",
       "User_12      0.0      0.0      0.0      1.0      0.0      0.0     10.0   \n",
       "User_13      0.0      0.0      0.0      3.0      0.0      0.0      7.0   \n",
       "User_14      3.0      0.0      0.0      0.0      0.0     10.0      0.0   \n",
       "User_15      9.0      0.0      0.0      0.0      4.0      0.0      0.0   \n",
       "\n",
       "         Filme_8  \n",
       "User_1       0.0  \n",
       "User_2       8.0  \n",
       "User_3       0.0  \n",
       "User_4       1.0  \n",
       "User_5       0.0  \n",
       "User_6       0.0  \n",
       "User_7       0.0  \n",
       "User_8       0.0  \n",
       "User_9       0.0  \n",
       "User_10      0.0  \n",
       "User_11      0.0  \n",
       "User_12      0.0  \n",
       "User_13      0.0  \n",
       "User_14      0.0  \n",
       "User_15      0.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(val, columns = df.columns, index = df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Exercício:\n",
    "\n",
    "Carregue o conjunto de dados a partir da função getData() e utilize o modelo de fatoração matricial.\n",
    "\n",
    "Faça uma divisão dos dados em treino/validação/teste de acordo com a metodologia acima discutida (Utilize qtd = 2, ou seja, 2 interações por usuário serão retiradas na divisão dos dados). \n",
    "\n",
    "Testando vários conjuntos de parâmetros - isto é, um análogo ao Grid Search de modelos - encontre a melhor fatoração matricial para realizarmos recomendações neste dataset.\n",
    "\n",
    "Obs.: esse grid search acima pode ser feito manualmente, implementado num loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(367, 80)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filme_1</th>\n",
       "      <th>Filme_2</th>\n",
       "      <th>Filme_3</th>\n",
       "      <th>Filme_4</th>\n",
       "      <th>Filme_5</th>\n",
       "      <th>Filme_6</th>\n",
       "      <th>Filme_7</th>\n",
       "      <th>Filme_8</th>\n",
       "      <th>Filme_9</th>\n",
       "      <th>Filme_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Filme_71</th>\n",
       "      <th>Filme_72</th>\n",
       "      <th>Filme_73</th>\n",
       "      <th>Filme_74</th>\n",
       "      <th>Filme_75</th>\n",
       "      <th>Filme_76</th>\n",
       "      <th>Filme_77</th>\n",
       "      <th>Filme_78</th>\n",
       "      <th>Filme_79</th>\n",
       "      <th>Filme_80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User_0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_362</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_363</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_364</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_365</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_366</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Filme_1  Filme_2  Filme_3  Filme_4  Filme_5  Filme_6  Filme_7  \\\n",
       "User_0        5.0      3.0      4.0      3.0      3.0      5.0      4.0   \n",
       "User_1        4.0      3.0      NaN      NaN      NaN      NaN      NaN   \n",
       "User_2        4.0      NaN      NaN      NaN      NaN      NaN      2.0   \n",
       "User_3        NaN      NaN      NaN      5.0      NaN      NaN      5.0   \n",
       "User_4        4.0      NaN      NaN      4.0      NaN      NaN      4.0   \n",
       "...           ...      ...      ...      ...      ...      ...      ...   \n",
       "User_362      3.0      NaN      NaN      3.0      NaN      NaN      4.0   \n",
       "User_363      2.0      4.0      NaN      5.0      NaN      NaN      NaN   \n",
       "User_364      4.0      NaN      4.0      NaN      NaN      5.0      4.0   \n",
       "User_365      NaN      NaN      NaN      2.0      NaN      NaN      4.0   \n",
       "User_366      NaN      5.0      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "          Filme_8  Filme_9  Filme_10  ...  Filme_71  Filme_72  Filme_73  \\\n",
       "User_0        1.0      5.0       3.0  ...       3.0       4.0       3.0   \n",
       "User_1        NaN      NaN       NaN  ...       NaN       NaN       NaN   \n",
       "User_2        4.0      4.0       NaN  ...       4.0       NaN       NaN   \n",
       "User_3        5.0      5.0       4.0  ...       5.0       5.0       3.0   \n",
       "User_4        NaN      4.0       NaN  ...       NaN       NaN       NaN   \n",
       "...           ...      ...       ...  ...       ...       ...       ...   \n",
       "User_362      NaN      3.0       NaN  ...       NaN       3.0       4.0   \n",
       "User_363      NaN      NaN       NaN  ...       NaN       3.0       NaN   \n",
       "User_364      NaN      4.0       NaN  ...       NaN       NaN       NaN   \n",
       "User_365      5.0      3.0       NaN  ...       NaN       NaN       NaN   \n",
       "User_366      NaN      3.0       NaN  ...       NaN       2.0       3.0   \n",
       "\n",
       "          Filme_74  Filme_75  Filme_76  Filme_77  Filme_78  Filme_79  Filme_80  \n",
       "User_0         1.0       4.0       4.0       4.0       1.0       4.0       4.0  \n",
       "User_1         NaN       NaN       NaN       NaN       NaN       3.0       2.0  \n",
       "User_2         NaN       NaN       NaN       NaN       NaN       3.0       NaN  \n",
       "User_3         NaN       NaN       NaN       5.0       3.0       4.0       4.0  \n",
       "User_4         NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "...            ...       ...       ...       ...       ...       ...       ...  \n",
       "User_362       NaN       NaN       NaN       NaN       NaN       3.0       2.0  \n",
       "User_363       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "User_364       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "User_365       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "User_366       NaN       NaN       4.0       NaN       NaN       5.0       2.0  \n",
       "\n",
       "[367 rows x 80 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = getData()\n",
    "print(R.shape)\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 1., 4., 4.],\n",
       "       [4., 3., 0., ..., 0., 3., 2.],\n",
       "       [4., 0., 0., ..., 0., 3., 0.],\n",
       "       ...,\n",
       "       [4., 0., 4., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 5., 2.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preenchendo os valores nulos com zero\n",
    "ratings = R.fillna(0).values\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando a função train_test_split definida no notebook, separaremos os dados em treino, validação e teste.\n",
    "train, test = train_test_split(ratings, qtd = 2)\n",
    "train, val = train_test_split(train, qtd = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar os dataframes de treino, validação e teste\n",
    "def getDataFrame(train_data, val_data, test_data, columns_name, index_name):\n",
    "    dfa = pd.DataFrame(np.c_[train_data], columns = columns_name, index = index_name)\n",
    "    dfb = pd.DataFrame(np.c_[val_data], columns = columns_name, index = index_name)\n",
    "    dfc = pd.DataFrame(np.c_[test_data], columns = columns_name, index = index_name)\n",
    "\n",
    "    return dfa, dfb, dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain, dfval, dftest = getDataFrame(train_data = train, val_data = val, test_data = test,\n",
    "                                     columns_name = R.columns, index_name = R.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de usar a classe \"MatrixFactorization\", faremos uma modificação inserindo um novo critério de parada. Esse novo critério irá comparar o valor MSE do step atual com o MSE do step anterior. Se a diferença entre os dois for menor que 0.001 ( ou 0,1%), o ajuste para, caso contrário, ele irá continuar até a quantidade de steps especificada. É evidente que caso o novo critério de parada seja muito grande, o ajuste nunca será adequado a nenhum dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class MatrixFactorization_mod():\n",
    "    \n",
    "    def __init__(self, dataframe, K, steps, alpha, beta, print_info = False):\n",
    "        self.df = dataframe\n",
    "        self.K = K\n",
    "        self.steps = steps\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.print_info = print_info\n",
    "        \n",
    "    def fit(self):\n",
    "        t0 = time.time()\n",
    "        \n",
    "        R = self.df.values\n",
    "        N, M = R.shape\n",
    "        \n",
    "        #inicio aleatorio\n",
    "        P = np.random.rand(N,self.K)\n",
    "        Q = np.random.rand(self.K,M)\n",
    "        \n",
    "        lista_erro_step = []\n",
    "        dif = 1\n",
    "        #loop\n",
    "        for step in range(self.steps):\n",
    "            if dif > 0.001:\n",
    "                mse_total_step = 0\n",
    "                #varrendo todas as entradas da matriz R\n",
    "                for i in range(len(R)):\n",
    "                    for j in range(len(R[i])):\n",
    "                        #validando se o valor associado está preenchido\n",
    "                        if R[i][j] > 0:\n",
    "\n",
    "                            #calculando o erro:\n",
    "                            eij = R[i][j] - np.dot(P[i,:],Q[:,j])\n",
    "                            mse_total_step += (eij)**2\n",
    "                            #alterando os valores\n",
    "                            for k in range(self.K):\n",
    "                                P[i][k] = P[i][k] + self.alpha * ( 2 * eij * Q[k][j] - self.beta * P[i][k])\n",
    "                                Q[k][j] = Q[k][j] + self.alpha * ( 2 * eij * P[i][k] - self.beta * Q[k][j])\n",
    "\n",
    "                if step != 0:\n",
    "                    dif = 1 - mse_total_step / lista_erro_step[-1]\n",
    "                lista_erro_step.append(mse_total_step)\n",
    "            else:\n",
    "                self.steps = step\n",
    "                break\n",
    "                \n",
    "        self.P = P\n",
    "        self.Q = Q\n",
    "        self.lista_erro_step = lista_erro_step\n",
    "        t1 = time.time()\n",
    "        if self.print_info:\n",
    "            print(\"Fatoração concluída. Tempo aproximado:\", int(t1-t0), 'segundos.')\n",
    "        \n",
    "    def predict(self):\n",
    "        return self.P.dot(self.Q)\n",
    "    \n",
    "    def print_MSE_steps(self):\n",
    "        plt.figure(figsize=[15,6])\n",
    "        plt.title(\"Custo total por Step\", fontsize = 16, fontweight = 'bold')\n",
    "        plt.xlabel(\"Step\", fontsize = 14, fontweight = 'bold')\n",
    "        plt.ylabel(\"Erro\", fontsize = 14, fontweight = 'bold')\n",
    "        plt.plot(range(1, 1+self.steps), self.lista_erro_step, c = 'blue', lw = 2)\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testar a modificação da função, que agora será chamada \"MatrixFactorization_mod\" para podermos diferenciá-la da classe apresentada no início do notebook, faremos um teste simples considerando os seguintes parâmetros abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instanciando o modelo\n",
    "fat = MatrixFactorization_mod(dataframe = dftrain, K = 5, steps = 500, alpha = 0.0001, beta = 0.2)\n",
    "\n",
    "# Ajustando o modelo aos dados\n",
    "fat.fit()\n",
    "\n",
    "# Imprimindo o gráfico do erro em função dos passos\n",
    "fat.print_MSE_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A diferente entre o valor do último coeficiente MSE calculado, comparado ao anterior é igual a 0.000979\n"
     ]
    }
   ],
   "source": [
    "print('A diferente entre o valor do último coeficiente MSE calculado, comparado ao anterior é igual a %s' \\\n",
    "%str(round(1 - (fat.lista_erro_step[-1] / fat.lista_erro_step[-2]), 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Vemos que o modelo alcançou um patamar para o MSE após 125 passos (o valor varia sempre que o notebook é resetado e rodado), aproximadamente, dessa maneira, evitamos passos desnecessários e otimizamos o tempo de fatoração. Da mesma forma, testaremos agora com apenas 50 passos para a mesma configuração anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instanciando o modelo\n",
    "fat = MatrixFactorization_mod(dataframe = dftrain, K = 5, steps = 50, alpha = 0.0001, beta = 0.2)\n",
    "\n",
    "# Ajustando o modelo aos dados\n",
    "fat.fit()\n",
    "\n",
    "# Imprimindo o gráfico do erro em função dos passos\n",
    "fat.print_MSE_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A diferente entre o valor do último coeficiente MSE calculado, comparado ao anterior é igual a 0.009683\n"
     ]
    }
   ],
   "source": [
    "print('A diferente entre o valor do último coeficiente MSE calculado, comparado ao anterior é igual a %s' \\\n",
    "%str(round(1 - (fat.lista_erro_step[-1] / fat.lista_erro_step[-2]), 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esse caso, como a diferença é superior ao valor padrão 0.001, a fatoração foi executada até o número de passos informado. Com isso em mente, consideraremos que o número de passos máximo será de 5000 e faremos uma busca pelos outros parâmetros para encontrar o melhor ajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de execução aproximado: 5363.0 segundos.\n"
     ]
    }
   ],
   "source": [
    "# Definindo intervalos\n",
    "K_lista = [5, 10]\n",
    "alpha_lista = np.linspace(0.0001, 0.01, 10)\n",
    "beta_lista = np.linspace(0.1, 0.2, 10)\n",
    "num_steps = 5000\n",
    "\n",
    "# Listas para armazenar valores de cada parâmetro\n",
    "lista_K = []\n",
    "lista_alpha = []\n",
    "lista_beta = []\n",
    "lista_steps = []\n",
    "lista_mse_train = []\n",
    "lista_mse_val = []\n",
    "\n",
    "t0 = time.time()\n",
    "for item1 in K_lista:\n",
    "    for item2 in alpha_lista:\n",
    "        for item3 in beta_lista:\n",
    "            # Instanciando modelo\n",
    "            fat = MatrixFactorization_mod(dataframe = dftrain,\n",
    "                                          K = item1,\n",
    "                                          steps = num_steps,\n",
    "                                          alpha = item2,\n",
    "                                          beta = item3)\n",
    "            \n",
    "            # Ajustando modelo\n",
    "            fat.fit()\n",
    "            \n",
    "            # Valores preditos\n",
    "            predicted_values = fat.predict()\n",
    "            \n",
    "            # Valores de validação para comparação\n",
    "            val_values = dfval.values\n",
    "            \n",
    "            rows_number, columns_number = val_values.shape\n",
    "            mse_val = 0\n",
    "            \n",
    "            for i in range(0, rows_number):\n",
    "                \n",
    "                for j in range(0, columns_number):\n",
    "                    # O erro só será calculado para os valores diferentes de zero dos dados de validação\n",
    "                    if (val_values[i][j] != 0):\n",
    "                        \n",
    "                        #calculando o erro:\n",
    "                        eij = predicted_values[i][j] - val_values[i][j]\n",
    "                        mse_val += (eij)**2          \n",
    "            \n",
    "            lista_K.append(item1)\n",
    "            lista_alpha.append(item2)\n",
    "            lista_steps.append(fat.steps)\n",
    "            lista_beta.append(item3)\n",
    "            lista_mse_train.append(fat.lista_erro_step[-1])\n",
    "            lista_mse_val.append(mse_val)\n",
    "\n",
    "# Construindo um dataframe a partir dos valores obtidos.\n",
    "\n",
    "df_resultados = pd.DataFrame(np.c_[lista_K, lista_alpha, lista_steps, lista_beta, lista_mse_train, lista_mse_val],\n",
    "                            columns = ['K', 'Alpha', 'Steps', 'Beta', 'MSE_train', 'MSE_val'])\n",
    "\n",
    "df_resultados['Diff_MSE'] = df_resultados['MSE_train'] - df_resultados['MSE_val']\n",
    "\n",
    "t1 = time.time()\n",
    "print('Tempo de execução aproximado: %s segundos.' %(str(round(t1 - t0, 0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Steps</th>\n",
       "      <th>Beta</th>\n",
       "      <th>MSE_train</th>\n",
       "      <th>MSE_val</th>\n",
       "      <th>Diff_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>2829.480150</td>\n",
       "      <td>714.997858</td>\n",
       "      <td>2114.482292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2908.601084</td>\n",
       "      <td>701.271979</td>\n",
       "      <td>2207.329105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2218.124236</td>\n",
       "      <td>792.904563</td>\n",
       "      <td>1425.219673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2324.375846</td>\n",
       "      <td>799.405411</td>\n",
       "      <td>1524.970435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>2408.583848</td>\n",
       "      <td>812.103393</td>\n",
       "      <td>1596.480455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        K   Alpha  Steps      Beta    MSE_train     MSE_val     Diff_MSE\n",
       "138  10.0  0.0034  171.0  0.188889  2829.480150  714.997858  2114.482292\n",
       "139  10.0  0.0034  163.0  0.200000  2908.601084  701.271979  2207.329105\n",
       "140  10.0  0.0045  151.0  0.100000  2218.124236  792.904563  1425.219673\n",
       "141  10.0  0.0045  145.0  0.111111  2324.375846  799.405411  1524.970435\n",
       "142  10.0  0.0045  145.0  0.122222  2408.583848  812.103393  1596.480455"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = df_resultados['MSE_train'] == df_resultados['MSE_train'].min()\n",
    "index = df_resultados.index[condition][0]\n",
    "\n",
    "df_resultados.iloc[index - 2: index + 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Steps</th>\n",
       "      <th>Beta</th>\n",
       "      <th>MSE_train</th>\n",
       "      <th>MSE_val</th>\n",
       "      <th>Diff_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>4134.542683</td>\n",
       "      <td>654.192886</td>\n",
       "      <td>3480.349797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>4183.556866</td>\n",
       "      <td>657.063560</td>\n",
       "      <td>3526.493306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>4209.480234</td>\n",
       "      <td>645.869182</td>\n",
       "      <td>3563.611052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>4302.821194</td>\n",
       "      <td>657.170509</td>\n",
       "      <td>3645.650685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5820.419193</td>\n",
       "      <td>649.978142</td>\n",
       "      <td>5170.441051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      K   Alpha  Steps      Beta    MSE_train     MSE_val     Diff_MSE\n",
       "15  5.0  0.0012  217.0  0.155556  4134.542683  654.192886  3480.349797\n",
       "16  5.0  0.0012  216.0  0.166667  4183.556866  657.063560  3526.493306\n",
       "17  5.0  0.0012  217.0  0.177778  4209.480234  645.869182  3563.611052\n",
       "18  5.0  0.0012  214.0  0.188889  4302.821194  657.170509  3645.650685\n",
       "19  5.0  0.0012   33.0  0.200000  5820.419193  649.978142  5170.441051"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_val = df_resultados['MSE_val'] == df_resultados['MSE_val'].min()\n",
    "index_val = df_resultados.index[condition_val][0]\n",
    "\n",
    "df_resultados.iloc[index_val - 2: index_val + 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Steps</th>\n",
       "      <th>Beta</th>\n",
       "      <th>MSE_train</th>\n",
       "      <th>MSE_val</th>\n",
       "      <th>Diff_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>2788.252140</td>\n",
       "      <td>734.864792</td>\n",
       "      <td>2053.387348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2914.685887</td>\n",
       "      <td>716.375072</td>\n",
       "      <td>2198.310815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2269.340110</td>\n",
       "      <td>883.426763</td>\n",
       "      <td>1385.913347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2308.687674</td>\n",
       "      <td>828.536701</td>\n",
       "      <td>1480.150972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>2405.376544</td>\n",
       "      <td>851.142988</td>\n",
       "      <td>1554.233556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        K   Alpha  Steps      Beta    MSE_train     MSE_val     Diff_MSE\n",
       "168  10.0  0.0067  111.0  0.188889  2788.252140  734.864792  2053.387348\n",
       "169  10.0  0.0067  110.0  0.200000  2914.685887  716.375072  2198.310815\n",
       "170  10.0  0.0078  125.0  0.100000  2269.340110  883.426763  1385.913347\n",
       "171  10.0  0.0078  117.0  0.111111  2308.687674  828.536701  1480.150972\n",
       "172  10.0  0.0078  103.0  0.122222  2405.376544  851.142988  1554.233556"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = df_resultados['Diff_MSE'] == df_resultados['Diff_MSE'].min()\n",
    "index = df_resultados.index[condition][0]\n",
    "\n",
    "df_resultados.iloc[index - 2: index + 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nos dataframes acima, vemos que quando o valor da MSE_train é mínimo, obtemos um valor elevado para o MSE_val e vice-versa. Com isso em mente, para selecionar os melhores parâmetros, consideraremos a média harmônica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Steps</th>\n",
       "      <th>Beta</th>\n",
       "      <th>MSE_train</th>\n",
       "      <th>MSE_val</th>\n",
       "      <th>Diff_MSE</th>\n",
       "      <th>MedHarm_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>2803.156033</td>\n",
       "      <td>717.861387</td>\n",
       "      <td>2085.294646</td>\n",
       "      <td>1143.009100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>2908.473086</td>\n",
       "      <td>699.640482</td>\n",
       "      <td>2208.832603</td>\n",
       "      <td>1127.949813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2927.716792</td>\n",
       "      <td>668.298918</td>\n",
       "      <td>2259.417873</td>\n",
       "      <td>1088.198786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2290.426630</td>\n",
       "      <td>784.110853</td>\n",
       "      <td>1506.315777</td>\n",
       "      <td>1168.272229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2310.608829</td>\n",
       "      <td>824.983709</td>\n",
       "      <td>1485.625121</td>\n",
       "      <td>1215.856090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        K   Alpha  Steps      Beta    MSE_train     MSE_val     Diff_MSE  \\\n",
       "127  10.0  0.0023  212.0  0.177778  2803.156033  717.861387  2085.294646   \n",
       "128  10.0  0.0023  201.0  0.188889  2908.473086  699.640482  2208.832603   \n",
       "129  10.0  0.0023  212.0  0.200000  2927.716792  668.298918  2259.417873   \n",
       "130  10.0  0.0034  176.0  0.100000  2290.426630  784.110853  1506.315777   \n",
       "131  10.0  0.0034  188.0  0.111111  2310.608829  824.983709  1485.625121   \n",
       "\n",
       "     MedHarm_MSE  \n",
       "127  1143.009100  \n",
       "128  1127.949813  \n",
       "129  1088.198786  \n",
       "130  1168.272229  \n",
       "131  1215.856090  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados['MedHarm_MSE'] = 2 * df_resultados['MSE_train'] * df_resultados['MSE_val'] / (df_resultados['MSE_train'] + df_resultados['MSE_val'])\n",
    "\n",
    "condition = df_resultados['MedHarm_MSE'] == df_resultados['MedHarm_MSE'].min()\n",
    "index = df_resultados.index[condition][0]\n",
    "\n",
    "df_resultados.iloc[index - 2: index + 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na linha 129 temos o caso com a menor média harmônica. Aplicaremos os parâmetros ao modelo e testaremos com os dados de teste. Após isso, avaliaremos a MSE e compararemos com o valor MSE_val obtido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "673.1243308699228"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fat_a = MatrixFactorization_mod(dataframe = dftrain,\n",
    "                                K = 10,\n",
    "                                steps = num_steps,\n",
    "                                alpha = 0.0023,\n",
    "                                beta = 0.2)\n",
    "# Ajustando modelo\n",
    "fat_a.fit()\n",
    "            \n",
    "# Valores preditos\n",
    "predicted_values_a = fat_a.predict()\n",
    "            \n",
    "# Valores de validação para comparação\n",
    "test_values = dftest.values\n",
    "            \n",
    "rows_number, columns_number = test_values.shape\n",
    "mse_test = 0            \n",
    "for i in range(0, rows_number):\n",
    "    for j in range(0, columns_number):\n",
    "    # O erro só será calculado para os valores diferentes de zero dos dados de validação\n",
    "        if (test_values[i][j] != 0): \n",
    "            #calculando o erro:\n",
    "            eij = predicted_values_a[i][j] - test_values[i][j]\n",
    "            mse_test += (eij)**2\n",
    "            \n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dataframes com os valores preditos, de validação e de teste\n",
    "df_pred_a = pd.DataFrame(np.c_[predicted_values_a], columns = R.columns, index = R.index)\n",
    "df_val = pd.DataFrame(np.c_[val_values], columns = R.columns, index = R.index)\n",
    "df_test = pd.DataFrame(np.c_[test_values], columns = R.columns, index = R.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecionando usuários aleatoriamente nos dados para verificar se podemos usar o modelo para recomendação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** User_171 **********\n",
      "Filme_2\n",
      "Valor predito:  3.5477032797731525\n",
      "Valor real:  2.0\n",
      "Diferença:  -77.38516398865762 %\n",
      "\n",
      "Filme_56\n",
      "Valor predito:  4.0011767360700405\n",
      "Valor real:  5.0\n",
      "Diferença:  19.976465278599186 %\n",
      "\n",
      "********** User_27 **********\n",
      "Filme_8\n",
      "Valor predito:  3.7428215053813636\n",
      "Valor real:  4.0\n",
      "Diferença:  6.42946236546591 %\n",
      "\n",
      "Filme_24\n",
      "Valor predito:  3.4306904898817474\n",
      "Valor real:  4.0\n",
      "Diferença:  14.232737752956314 %\n",
      "\n",
      "********** User_8 **********\n",
      "Filme_58\n",
      "Valor predito:  4.537321730746478\n",
      "Valor real:  4.0\n",
      "Diferença:  -13.433043268661947 %\n",
      "\n",
      "Filme_76\n",
      "Valor predito:  3.62020342250548\n",
      "Valor real:  5.0\n",
      "Diferença:  27.595931549890395 %\n",
      "\n",
      "********** User_229 **********\n",
      "Filme_42\n",
      "Valor predito:  3.678780313092665\n",
      "Valor real:  3.0\n",
      "Diferença:  -22.626010436422163 %\n",
      "\n",
      "Filme_49\n",
      "Valor predito:  2.3321233641876993\n",
      "Valor real:  2.0\n",
      "Diferença:  -16.606168209384965 %\n",
      "\n",
      "********** User_240 **********\n",
      "Filme_5\n",
      "Valor predito:  3.4722331918846536\n",
      "Valor real:  4.0\n",
      "Diferença:  13.19417020288366 %\n",
      "\n",
      "Filme_11\n",
      "Valor predito:  4.016824837704793\n",
      "Valor real:  4.0\n",
      "Diferença:  -0.4206209426198315 %\n",
      "\n",
      "********** User_327 **********\n",
      "Filme_45\n",
      "Valor predito:  3.922225413788732\n",
      "Valor real:  4.0\n",
      "Diferença:  1.944364655281705 %\n",
      "\n",
      "Filme_56\n",
      "Valor predito:  4.4510818969277235\n",
      "Valor real:  4.0\n",
      "Diferença:  -11.277047423193087 %\n",
      "\n",
      "********** User_150 **********\n",
      "Filme_10\n",
      "Valor predito:  4.101743141624437\n",
      "Valor real:  3.0\n",
      "Diferença:  -36.72477138748125 %\n",
      "\n",
      "Filme_15\n",
      "Valor predito:  3.925833108069151\n",
      "Valor real:  4.0\n",
      "Diferença:  1.8541722982712283 %\n",
      "\n",
      "********** User_216 **********\n",
      "Filme_11\n",
      "Valor predito:  4.418341990507983\n",
      "Valor real:  5.0\n",
      "Diferença:  11.633160189840341 %\n",
      "\n",
      "Filme_22\n",
      "Valor predito:  5.1511859563196065\n",
      "Valor real:  5.0\n",
      "Diferença:  -3.0237191263921215 %\n",
      "\n",
      "********** User_356 **********\n",
      "Filme_31\n",
      "Valor predito:  3.77764048363367\n",
      "Valor real:  3.0\n",
      "Diferença:  -25.921349454455655 %\n",
      "\n",
      "Filme_50\n",
      "Valor predito:  3.859029373301981\n",
      "Valor real:  3.0\n",
      "Diferença:  -28.634312443399356 %\n",
      "\n",
      "********** User_157 **********\n",
      "Filme_12\n",
      "Valor predito:  4.388610175324464\n",
      "Valor real:  5.0\n",
      "Diferença:  12.227796493510713 %\n",
      "\n",
      "Filme_61\n",
      "Valor predito:  4.103667974237721\n",
      "Valor real:  5.0\n",
      "Diferença:  17.926640515245573 %\n",
      "\n",
      "********** User_142 **********\n",
      "Filme_22\n",
      "Valor predito:  4.027276896945494\n",
      "Valor real:  5.0\n",
      "Diferença:  19.454462061090116 %\n",
      "\n",
      "Filme_31\n",
      "Valor predito:  3.3456448165097714\n",
      "Valor real:  5.0\n",
      "Diferença:  33.08710366980458 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = np.random.randint(0, df_test.shape[0], size=11)\n",
    "\n",
    "for i in index:\n",
    "    print('*' * 10 + ' ' + df_test.index[i] + ' ' + '*' * 10)\n",
    "    condition = df_test.iloc[i, :] != 0\n",
    "\n",
    "    j = 0\n",
    "    for item in condition:\n",
    "\n",
    "        if item:\n",
    "            print(df_test.columns[j])\n",
    "            print('Valor predito: ', end= ' ')\n",
    "            print(df_pred_a.iloc[i, j], end='\\n')\n",
    "            print('Valor real: ', end= ' ')\n",
    "            print(df_test.iloc[i, j], end='\\n')\n",
    "            print('Diferença: ', end=' ')\n",
    "            print((1 - df_pred_a.iloc[i, j]/df_test.iloc[i, j]) * 100, end=' ')\n",
    "            print('%', end='\\n\\n')\n",
    "            j += 1\n",
    "        else:\n",
    "            j += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem casos que apresentam grandes diferenças, como -77%, assim como aqueles que apresentam uma pequena diferença, como 2%. Os usuários acima representam 3% da população total de amostras. Entretanto, existem casos em que a diferença entre o valor predito e o valor de teste é de 200%. Vejamos se o modelo ajustado com os parâmetros que fornecem o menor valor de MSE_val apresenta melhores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "645.6511901268149"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fat_b = MatrixFactorization_mod(dataframe = dftrain,\n",
    "                                K = 5,\n",
    "                                steps = num_steps,\n",
    "                                alpha = 0.0012,\n",
    "                                beta = 0.177778)\n",
    "# Ajustando modelo\n",
    "fat_b.fit()\n",
    "            \n",
    "# Valores preditos\n",
    "predicted_values_b = fat_b.predict()\n",
    "            \n",
    "# Valores de validação para comparação\n",
    "test_values = dftest.values\n",
    "            \n",
    "rows_number, columns_number = test_values.shape\n",
    "mse_test = 0            \n",
    "for i in range(0, rows_number):\n",
    "    for j in range(0, columns_number):\n",
    "    # O erro só será calculado para os valores diferentes de zero dos dados de validação\n",
    "        if (test_values[i][j] != 0): \n",
    "            #calculando o erro:\n",
    "            eij = predicted_values_b[i][j] - test_values[i][j]\n",
    "            mse_test += (eij)**2\n",
    "            \n",
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que o valor para o MSE para os dados de teste diminuiram em relação ao caso anterior. Vejamos como as predições se comportam, quando comparadas aos dados de testes selecionando alguns usuários aleatórios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dataframe com os valores preditos\n",
    "df_pred_b = pd.DataFrame(np.c_[predicted_values_b], columns = R.columns, index = R.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** User_134 **********\n",
      "Filme_11\n",
      "Valor predito:  3.4774876105967762\n",
      "Valor real:  4.0\n",
      "Diferença:  13.062809735080593 %\n",
      "\n",
      "Filme_44\n",
      "Valor predito:  3.1329620287052835\n",
      "Valor real:  4.0\n",
      "Diferença:  21.675949282367913 %\n",
      "\n",
      "********** User_335 **********\n",
      "Filme_73\n",
      "Valor predito:  3.2922437451914304\n",
      "Valor real:  1.0\n",
      "Diferença:  -229.22437451914303 %\n",
      "\n",
      "Filme_80\n",
      "Valor predito:  2.580182571790588\n",
      "Valor real:  2.0\n",
      "Diferença:  -29.009128589529396 %\n",
      "\n",
      "********** User_188 **********\n",
      "Filme_3\n",
      "Valor predito:  2.370645143515755\n",
      "Valor real:  2.0\n",
      "Diferença:  -18.53225717578775 %\n",
      "\n",
      "Filme_7\n",
      "Valor predito:  2.952703648280516\n",
      "Valor real:  4.0\n",
      "Diferença:  26.1824087929871 %\n",
      "\n",
      "********** User_15 **********\n",
      "Filme_58\n",
      "Valor predito:  3.5875596943191828\n",
      "Valor real:  3.0\n",
      "Diferença:  -19.585323143972765 %\n",
      "\n",
      "Filme_64\n",
      "Valor predito:  4.382275129289347\n",
      "Valor real:  5.0\n",
      "Diferença:  12.35449741421306 %\n",
      "\n",
      "********** User_49 **********\n",
      "Filme_12\n",
      "Valor predito:  3.9598527832339223\n",
      "Valor real:  4.0\n",
      "Diferença:  1.0036804191519422 %\n",
      "\n",
      "Filme_38\n",
      "Valor predito:  2.6484705926220347\n",
      "Valor real:  3.0\n",
      "Diferença:  11.717646912598845 %\n",
      "\n",
      "********** User_248 **********\n",
      "Filme_62\n",
      "Valor predito:  3.3034805576809636\n",
      "Valor real:  4.0\n",
      "Diferença:  17.41298605797591 %\n",
      "\n",
      "Filme_71\n",
      "Valor predito:  4.117128798290708\n",
      "Valor real:  3.0\n",
      "Diferença:  -37.23762660969028 %\n",
      "\n",
      "********** User_203 **********\n",
      "Filme_28\n",
      "Valor predito:  4.048117740938242\n",
      "Valor real:  2.0\n",
      "Diferença:  -102.40588704691208 %\n",
      "\n",
      "Filme_68\n",
      "Valor predito:  3.3429688173399845\n",
      "Valor real:  4.0\n",
      "Diferença:  16.42577956650039 %\n",
      "\n",
      "********** User_106 **********\n",
      "Filme_15\n",
      "Valor predito:  4.05120014370508\n",
      "Valor real:  4.0\n",
      "Diferença:  -1.2800035926270104 %\n",
      "\n",
      "Filme_69\n",
      "Valor predito:  4.044105644592369\n",
      "Valor real:  4.0\n",
      "Diferença:  -1.102641114809222 %\n",
      "\n",
      "********** User_54 **********\n",
      "Filme_7\n",
      "Valor predito:  4.236731228554211\n",
      "Valor real:  5.0\n",
      "Diferença:  15.265375428915783 %\n",
      "\n",
      "Filme_72\n",
      "Valor predito:  3.2820249815230107\n",
      "Valor real:  3.0\n",
      "Diferença:  -9.400832717433683 %\n",
      "\n",
      "********** User_200 **********\n",
      "Filme_9\n",
      "Valor predito:  3.473939545984387\n",
      "Valor real:  4.0\n",
      "Diferença:  13.151511350390322 %\n",
      "\n",
      "Filme_11\n",
      "Valor predito:  3.518642063170255\n",
      "Valor real:  1.0\n",
      "Diferença:  -251.86420631702552 %\n",
      "\n",
      "********** User_362 **********\n",
      "Filme_7\n",
      "Valor predito:  3.070296754653817\n",
      "Valor real:  4.0\n",
      "Diferença:  23.24258113365457 %\n",
      "\n",
      "Filme_56\n",
      "Valor predito:  3.2674680126529\n",
      "Valor real:  5.0\n",
      "Diferença:  34.650639746942005 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = np.random.randint(0, df_test.shape[0], size=11)\n",
    "\n",
    "for i in index:\n",
    "    print('*' * 10 + ' ' + df_test.index[i] + ' ' + '*' * 10)\n",
    "    condition = df_test.iloc[i, :] != 0\n",
    "\n",
    "    j = 0\n",
    "    for item in condition:\n",
    "\n",
    "        if item:\n",
    "            print(df_test.columns[j])\n",
    "            print('Valor predito: ', end= ' ')\n",
    "            print(df_pred_b.iloc[i, j], end='\\n')\n",
    "            print('Valor real: ', end= ' ')\n",
    "            print(df_test.iloc[i, j], end='\\n')\n",
    "            print('Diferença: ', end=' ')\n",
    "            print((1 - df_pred_b.iloc[i, j]/df_test.iloc[i, j]) * 100, end=' ')\n",
    "            print('%', end='\\n\\n')\n",
    "            j += 1\n",
    "        else:\n",
    "            j += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebemos que existem valores que apresentam diferença superior a 200%, assim como no caso anterior, e valores com pequenas diferenças, próximo de 1%. Como o ganho de desempenho não é significativo (os valores de MSE para os dados de teste são próximos), o modelo mais adequado para recomendação é o configurado com os seguintes parâmetros:\n",
    "\n",
    "- K = 10\n",
    "- $\\alpha$ = 0.0023\n",
    "- $\\beta$ = 0.2\n",
    "\n",
    "onde o número de steps depende da convergência do valor de MSE.\n",
    "\n",
    "Podemos realizar um teste aumentando a quantidade de dados que são selecionados dos dados originais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de execução aproximado: 5019.0 segundos.\n"
     ]
    }
   ],
   "source": [
    "# Usando a função train_test_split definida no notebook, separaremos os dados em treino, validação e teste.\n",
    "train, test = train_test_split(ratings, qtd = 4)\n",
    "train, val = train_test_split(train, qtd = 4)\n",
    "\n",
    "dftrain, dfval, dftest = getDataFrame(train_data = train, val_data = val, test_data = test,\n",
    "                                     columns_name = R.columns, index_name = R.index)\n",
    "\n",
    "# Definindo intervalos\n",
    "K_lista = [5, 10]\n",
    "alpha_lista = np.linspace(0.0001, 0.01, 10)\n",
    "beta_lista = np.linspace(0.1, 0.2, 10)\n",
    "num_steps = 5000\n",
    "\n",
    "# Listas para armazenar valores de cada parâmetro\n",
    "lista_K = []\n",
    "lista_alpha = []\n",
    "lista_beta = []\n",
    "lista_steps = []\n",
    "lista_mse_train = []\n",
    "lista_mse_val = []\n",
    "\n",
    "t0 = time.time()\n",
    "for item1 in K_lista:\n",
    "    for item2 in alpha_lista:\n",
    "        for item3 in beta_lista:\n",
    "            # Instanciando modelo\n",
    "            fat = MatrixFactorization_mod(dataframe = dftrain,\n",
    "                                          K = item1,\n",
    "                                          steps = num_steps,\n",
    "                                          alpha = item2,\n",
    "                                          beta = item3)\n",
    "            \n",
    "            # Ajustando modelo\n",
    "            fat.fit()\n",
    "            \n",
    "            # Valores preditos\n",
    "            predicted_values = fat.predict()\n",
    "            \n",
    "            # Valores de validação para comparação\n",
    "            val_values = dfval.values\n",
    "            \n",
    "            rows_number, columns_number = val_values.shape\n",
    "            mse_val = 0\n",
    "            \n",
    "            for i in range(0, rows_number):\n",
    "                \n",
    "                for j in range(0, columns_number):\n",
    "                    # O erro só será calculado para os valores diferentes de zero dos dados de validação\n",
    "                    if (val_values[i][j] != 0):\n",
    "                        \n",
    "                        #calculando o erro:\n",
    "                        eij = predicted_values[i][j] - val_values[i][j]\n",
    "                        mse_val += (eij)**2          \n",
    "            \n",
    "            lista_K.append(item1)\n",
    "            lista_alpha.append(item2)\n",
    "            lista_steps.append(fat.steps)\n",
    "            lista_beta.append(item3)\n",
    "            lista_mse_train.append(fat.lista_erro_step[-1])\n",
    "            lista_mse_val.append(mse_val)\n",
    "\n",
    "# Construindo um dataframe a partir dos valores obtidos.\n",
    "\n",
    "df_resultados = pd.DataFrame(np.c_[lista_K, lista_alpha, lista_steps, lista_beta, lista_mse_train, lista_mse_val],\n",
    "                            columns = ['K', 'Alpha', 'Steps', 'Beta', 'MSE_train', 'MSE_val'])\n",
    "\n",
    "df_resultados['Diff_MSE'] = df_resultados['MSE_train'] - df_resultados['MSE_val']\n",
    "\n",
    "t1 = time.time()\n",
    "print('Tempo de execução aproximado: %s segundos.' %(str(round(t1 - t0, 0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como no caso anterior, usaremos a média harmônica para avaliar o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Steps</th>\n",
       "      <th>Beta</th>\n",
       "      <th>MSE_train</th>\n",
       "      <th>MSE_val</th>\n",
       "      <th>Diff_MSE</th>\n",
       "      <th>MedHarm_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2095.332170</td>\n",
       "      <td>1456.417218</td>\n",
       "      <td>638.914952</td>\n",
       "      <td>1718.408320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1512.780116</td>\n",
       "      <td>1704.032508</td>\n",
       "      <td>-191.252392</td>\n",
       "      <td>1602.720951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1548.400242</td>\n",
       "      <td>1581.735698</td>\n",
       "      <td>-33.335456</td>\n",
       "      <td>1564.890461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>1648.027343</td>\n",
       "      <td>1633.363759</td>\n",
       "      <td>14.663584</td>\n",
       "      <td>1640.662787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1655.112345</td>\n",
       "      <td>1640.202967</td>\n",
       "      <td>14.909378</td>\n",
       "      <td>1647.623928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        K   Alpha  Steps      Beta    MSE_train      MSE_val    Diff_MSE  \\\n",
       "129  10.0  0.0023  227.0  0.200000  2095.332170  1456.417218  638.914952   \n",
       "130  10.0  0.0034  224.0  0.100000  1512.780116  1704.032508 -191.252392   \n",
       "131  10.0  0.0034  201.0  0.111111  1548.400242  1581.735698  -33.335456   \n",
       "132  10.0  0.0034  191.0  0.122222  1648.027343  1633.363759   14.663584   \n",
       "133  10.0  0.0034  189.0  0.133333  1655.112345  1640.202967   14.909378   \n",
       "\n",
       "     MedHarm_MSE  \n",
       "129  1718.408320  \n",
       "130  1602.720951  \n",
       "131  1564.890461  \n",
       "132  1640.662787  \n",
       "133  1647.623928  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados['MedHarm_MSE'] = 2 * df_resultados['MSE_train'] * df_resultados['MSE_val'] / (df_resultados['MSE_train'] + df_resultados['MSE_val'])\n",
    "\n",
    "condition = df_resultados['MedHarm_MSE'] == df_resultados['MedHarm_MSE'].min()\n",
    "index = df_resultados.index[condition][0]\n",
    "\n",
    "df_resultados.iloc[index - 2: index + 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1698.2585254699309"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fat_c = MatrixFactorization_mod(dataframe = dftrain,\n",
    "                                K = 10,\n",
    "                                steps = num_steps,\n",
    "                                alpha = 0.0034,\n",
    "                                beta = 0.111111)\n",
    "# Ajustando modelo\n",
    "fat_c.fit()\n",
    "            \n",
    "# Valores preditos\n",
    "predicted_values_c = fat_c.predict()\n",
    "            \n",
    "# Valores de validação para comparação\n",
    "test_values = dftest.values\n",
    "            \n",
    "rows_number, columns_number = test_values.shape\n",
    "mse_test = 0            \n",
    "for i in range(0, rows_number):\n",
    "    for j in range(0, columns_number):\n",
    "    # O erro só será calculado para os valores diferentes de zero dos dados de validação\n",
    "        if (test_values[i][j] != 0): \n",
    "            #calculando o erro:\n",
    "            eij = predicted_values_c[i][j] - test_values[i][j]\n",
    "            mse_test += (eij)**2\n",
    "            \n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dataframes com os valores preditos, de validação e de teste\n",
    "df_pred_c = pd.DataFrame(np.c_[predicted_values_c], columns = R.columns, index = R.index)\n",
    "df_val = pd.DataFrame(np.c_[val_values], columns = R.columns, index = R.index)\n",
    "df_test = pd.DataFrame(np.c_[test_values], columns = R.columns, index = R.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** User_211 **********\n",
      "Filme_13\n",
      "Valor predito:  3.6607867777126692\n",
      "Valor real:  3.0\n",
      "Diferença:  -22.02622592375565 %\n",
      "\n",
      "Filme_26\n",
      "Valor predito:  3.452520039499\n",
      "Valor real:  3.0\n",
      "Diferença:  -15.084001316633323 %\n",
      "\n",
      "Filme_64\n",
      "Valor predito:  4.485360441429654\n",
      "Valor real:  4.0\n",
      "Diferença:  -12.134011035741343 %\n",
      "\n",
      "Filme_79\n",
      "Valor predito:  4.659336746676982\n",
      "Valor real:  4.0\n",
      "Diferença:  -16.483418666924553 %\n",
      "\n",
      "********** User_245 **********\n",
      "Filme_8\n",
      "Valor predito:  3.993822092470231\n",
      "Valor real:  4.0\n",
      "Diferença:  0.15444768824423027 %\n",
      "\n",
      "Filme_50\n",
      "Valor predito:  4.59372006361719\n",
      "Valor real:  4.0\n",
      "Diferença:  -14.84300159042975 %\n",
      "\n",
      "Filme_71\n",
      "Valor predito:  3.130687236579128\n",
      "Valor real:  4.0\n",
      "Diferença:  21.732819085521804 %\n",
      "\n",
      "Filme_79\n",
      "Valor predito:  4.025060209933216\n",
      "Valor real:  3.0\n",
      "Diferença:  -34.16867366444052 %\n",
      "\n",
      "********** User_353 **********\n",
      "Filme_7\n",
      "Valor predito:  4.194641909545341\n",
      "Valor real:  2.0\n",
      "Diferença:  -109.73209547726705 %\n",
      "\n",
      "Filme_12\n",
      "Valor predito:  4.6729596829922215\n",
      "Valor real:  5.0\n",
      "Diferença:  6.540806340155569 %\n",
      "\n",
      "Filme_52\n",
      "Valor predito:  3.4864131892097547\n",
      "Valor real:  3.0\n",
      "Diferença:  -16.213772973658493 %\n",
      "\n",
      "Filme_56\n",
      "Valor predito:  5.194219841895959\n",
      "Valor real:  5.0\n",
      "Diferença:  -3.8843968379191685 %\n",
      "\n",
      "********** User_39 **********\n",
      "Filme_4\n",
      "Valor predito:  4.094719200243806\n",
      "Valor real:  5.0\n",
      "Diferença:  18.10561599512388 %\n",
      "\n",
      "Filme_11\n",
      "Valor predito:  3.777546478752668\n",
      "Valor real:  5.0\n",
      "Diferença:  24.44907042494664 %\n",
      "\n",
      "Filme_12\n",
      "Valor predito:  4.970888136060844\n",
      "Valor real:  5.0\n",
      "Diferença:  0.5822372787831265 %\n",
      "\n",
      "Filme_25\n",
      "Valor predito:  3.521971264070778\n",
      "Valor real:  3.0\n",
      "Diferença:  -17.39904213569259 %\n",
      "\n",
      "********** User_301 **********\n",
      "Filme_12\n",
      "Valor predito:  4.526455867887682\n",
      "Valor real:  5.0\n",
      "Diferença:  9.470882642246359 %\n",
      "\n",
      "Filme_29\n",
      "Valor predito:  2.2780835145718465\n",
      "Valor real:  3.0\n",
      "Diferença:  24.06388284760511 %\n",
      "\n",
      "Filme_33\n",
      "Valor predito:  3.1394087732673004\n",
      "Valor real:  4.0\n",
      "Diferença:  21.514780668317492 %\n",
      "\n",
      "Filme_62\n",
      "Valor predito:  2.7186053480580097\n",
      "Valor real:  2.0\n",
      "Diferença:  -35.93026740290048 %\n",
      "\n",
      "********** User_316 **********\n",
      "Filme_1\n",
      "Valor predito:  3.142714759203834\n",
      "Valor real:  4.0\n",
      "Diferença:  21.432131019904155 %\n",
      "\n",
      "Filme_2\n",
      "Valor predito:  2.8572873854571017\n",
      "Valor real:  3.0\n",
      "Diferença:  4.757087151429939 %\n",
      "\n",
      "Filme_24\n",
      "Valor predito:  2.9534728869784965\n",
      "Valor real:  3.0\n",
      "Diferença:  1.5509037673834491 %\n",
      "\n",
      "Filme_45\n",
      "Valor predito:  3.318868707617272\n",
      "Valor real:  4.0\n",
      "Diferença:  17.028282309568198 %\n",
      "\n",
      "********** User_92 **********\n",
      "Filme_15\n",
      "Valor predito:  3.32563373242314\n",
      "Valor real:  3.0\n",
      "Diferença:  -10.854457747438007 %\n",
      "\n",
      "Filme_22\n",
      "Valor predito:  3.9297041197690743\n",
      "Valor real:  4.0\n",
      "Diferença:  1.7573970057731425 %\n",
      "\n",
      "Filme_50\n",
      "Valor predito:  3.7149989131033037\n",
      "Valor real:  5.0\n",
      "Diferença:  25.70002173793393 %\n",
      "\n",
      "Filme_78\n",
      "Valor predito:  1.8242158639604928\n",
      "Valor real:  3.0\n",
      "Diferença:  39.192804534650236 %\n",
      "\n",
      "********** User_303 **********\n",
      "Filme_4\n",
      "Valor predito:  2.960760249762602\n",
      "Valor real:  3.0\n",
      "Diferença:  1.3079916745799225 %\n",
      "\n",
      "Filme_22\n",
      "Valor predito:  4.832589151233655\n",
      "Valor real:  4.0\n",
      "Diferença:  -20.814728780841385 %\n",
      "\n",
      "Filme_50\n",
      "Valor predito:  3.949364148598323\n",
      "Valor real:  3.0\n",
      "Diferença:  -31.64547161994411 %\n",
      "\n",
      "Filme_64\n",
      "Valor predito:  4.7254604900834805\n",
      "Valor real:  5.0\n",
      "Diferença:  5.490790198330386 %\n",
      "\n",
      "********** User_320 **********\n",
      "Filme_2\n",
      "Valor predito:  3.046680453259881\n",
      "Valor real:  3.0\n",
      "Diferença:  -1.5560151086627005 %\n",
      "\n",
      "Filme_29\n",
      "Valor predito:  2.1202747815380136\n",
      "Valor real:  3.0\n",
      "Diferença:  29.324173948732877 %\n",
      "\n",
      "Filme_39\n",
      "Valor predito:  3.6890941554152126\n",
      "Valor real:  4.0\n",
      "Diferença:  7.772646114619686 %\n",
      "\n",
      "Filme_62\n",
      "Valor predito:  2.7650070488838834\n",
      "Valor real:  4.0\n",
      "Diferença:  30.874823777902915 %\n",
      "\n",
      "********** User_55 **********\n",
      "Filme_55\n",
      "Valor predito:  3.5001955423427034\n",
      "Valor real:  4.0\n",
      "Diferença:  12.495111441432416 %\n",
      "\n",
      "Filme_59\n",
      "Valor predito:  4.836228958143969\n",
      "Valor real:  4.0\n",
      "Diferença:  -20.90572395359922 %\n",
      "\n",
      "Filme_61\n",
      "Valor predito:  4.306767185121993\n",
      "Valor real:  4.0\n",
      "Diferença:  -7.669179628049827 %\n",
      "\n",
      "Filme_79\n",
      "Valor predito:  3.2740689580761204\n",
      "Valor real:  4.0\n",
      "Diferença:  18.14827604809699 %\n",
      "\n",
      "********** User_157 **********\n",
      "Filme_8\n",
      "Valor predito:  4.263896676433631\n",
      "Valor real:  3.0\n",
      "Diferença:  -42.12988921445435 %\n",
      "\n",
      "Filme_9\n",
      "Valor predito:  4.198037263043002\n",
      "Valor real:  5.0\n",
      "Diferença:  16.039254739139963 %\n",
      "\n",
      "Filme_26\n",
      "Valor predito:  3.5357900993955167\n",
      "Valor real:  5.0\n",
      "Diferença:  29.284198012089668 %\n",
      "\n",
      "Filme_71\n",
      "Valor predito:  3.1700991854485685\n",
      "Valor real:  3.0\n",
      "Diferença:  -5.669972848285609 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = np.random.randint(0, df_test.shape[0], size=11)\n",
    "\n",
    "for i in index:\n",
    "    print('*' * 10 + ' ' + df_test.index[i] + ' ' + '*' * 10)\n",
    "    condition = df_test.iloc[i, :] != 0\n",
    "\n",
    "    j = 0\n",
    "    for item in condition:\n",
    "\n",
    "        if item:\n",
    "            print(df_test.columns[j])\n",
    "            print('Valor predito: ', end= ' ')\n",
    "            print(df_pred_c.iloc[i, j], end='\\n')\n",
    "            print('Valor real: ', end= ' ')\n",
    "            print(df_test.iloc[i, j], end='\\n')\n",
    "            print('Diferença: ', end=' ')\n",
    "            print((1 - df_pred_c.iloc[i, j]/df_test.iloc[i, j]) * 100, end=' ')\n",
    "            print('%', end='\\n\\n')\n",
    "            j += 1\n",
    "        else:\n",
    "            j += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aumentando a quantidade de itens armazenados para teste, validação e treino, vemos pelos resultados acima que o valor da MSE permanece aproximadamente o mesmo para os dados de treino e validação, enquanto apresenta um aumento de 9%. Através da amostragem acima, vemos que é possível alcançar valores com diferença de 0,01% até 150%\n",
    "\n",
    "Avaliando o modelo que apresenta menor valor para MSE_val, vemos que o valor para o MSE dos dados de treino é bastante elevado. Vejamos como o modelo se comporta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Steps</th>\n",
       "      <th>Beta</th>\n",
       "      <th>MSE_train</th>\n",
       "      <th>MSE_val</th>\n",
       "      <th>Diff_MSE</th>\n",
       "      <th>MedHarm_MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3170.049418</td>\n",
       "      <td>1514.902675</td>\n",
       "      <td>1655.146744</td>\n",
       "      <td>2050.102647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>4678.737746</td>\n",
       "      <td>1363.035175</td>\n",
       "      <td>3315.702571</td>\n",
       "      <td>2111.063823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>4648.243486</td>\n",
       "      <td>1354.006238</td>\n",
       "      <td>3294.237248</td>\n",
       "      <td>2097.130565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>4739.170793</td>\n",
       "      <td>1411.009764</td>\n",
       "      <td>3328.161030</td>\n",
       "      <td>2174.575591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>4699.170492</td>\n",
       "      <td>1387.893277</td>\n",
       "      <td>3311.277216</td>\n",
       "      <td>2142.887730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        K   Alpha  Steps      Beta    MSE_train      MSE_val     Diff_MSE  \\\n",
       "99    5.0  0.0100   71.0  0.200000  3170.049418  1514.902675  1655.146744   \n",
       "100  10.0  0.0001  136.0  0.100000  4678.737746  1363.035175  3315.702571   \n",
       "101  10.0  0.0001  138.0  0.111111  4648.243486  1354.006238  3294.237248   \n",
       "102  10.0  0.0001  140.0  0.122222  4739.170793  1411.009764  3328.161030   \n",
       "103  10.0  0.0001  135.0  0.133333  4699.170492  1387.893277  3311.277216   \n",
       "\n",
       "     MedHarm_MSE  \n",
       "99   2050.102647  \n",
       "100  2111.063823  \n",
       "101  2097.130565  \n",
       "102  2174.575591  \n",
       "103  2142.887730  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_val = df_resultados['MSE_val'] == df_resultados['MSE_val'].min()\n",
    "index_val = df_resultados.index[condition_val][0]\n",
    "\n",
    "df_resultados.iloc[index_val - 2: index_val + 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1446.3199331130397"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fat_c = MatrixFactorization_mod(dataframe = dftrain,\n",
    "                                K = 10,\n",
    "                                steps = num_steps,\n",
    "                                alpha = 0.0001,\n",
    "                                beta = 0.111111)\n",
    "# Ajustando modelo\n",
    "fat_c.fit()\n",
    "            \n",
    "# Valores preditos\n",
    "predicted_values_c = fat_c.predict()\n",
    "            \n",
    "# Valores de validação para comparação\n",
    "test_values = dftest.values\n",
    "            \n",
    "rows_number, columns_number = test_values.shape\n",
    "mse_test = 0            \n",
    "for i in range(0, rows_number):\n",
    "    for j in range(0, columns_number):\n",
    "    # O erro só será calculado para os valores diferentes de zero dos dados de validação\n",
    "        if (test_values[i][j] != 0): \n",
    "            #calculando o erro:\n",
    "            eij = predicted_values_c[i][j] - test_values[i][j]\n",
    "            mse_test += (eij)**2\n",
    "            \n",
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dataframes com os valores preditos, de validação e de teste\n",
    "df_pred_c = pd.DataFrame(np.c_[predicted_values_c], columns = R.columns, index = R.index)\n",
    "df_val = pd.DataFrame(np.c_[val_values], columns = R.columns, index = R.index)\n",
    "df_test = pd.DataFrame(np.c_[test_values], columns = R.columns, index = R.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** User_215 **********\n",
      "Filme_7\n",
      "Valor predito:  3.8266457502366173\n",
      "Valor real:  5.0\n",
      "Diferença:  23.46708499526765 %\n",
      "\n",
      "Filme_14\n",
      "Valor predito:  3.631094127602009\n",
      "Valor real:  2.0\n",
      "Diferença:  -81.55470638010046 %\n",
      "\n",
      "Filme_23\n",
      "Valor predito:  3.935078824706298\n",
      "Valor real:  5.0\n",
      "Diferença:  21.29842350587403 %\n",
      "\n",
      "Filme_56\n",
      "Valor predito:  3.843068195515864\n",
      "Valor real:  4.0\n",
      "Diferença:  3.9232951121033977 %\n",
      "\n",
      "********** User_189 **********\n",
      "Filme_1\n",
      "Valor predito:  3.9017784480506044\n",
      "Valor real:  4.0\n",
      "Diferença:  2.455538798734891 %\n",
      "\n",
      "Filme_8\n",
      "Valor predito:  3.6495998903151934\n",
      "Valor real:  4.0\n",
      "Diferença:  8.760002742120164 %\n",
      "\n",
      "Filme_12\n",
      "Valor predito:  3.8657272412899064\n",
      "Valor real:  4.0\n",
      "Diferença:  3.3568189677523397 %\n",
      "\n",
      "Filme_56\n",
      "Valor predito:  3.8037970728319888\n",
      "Valor real:  4.0\n",
      "Diferença:  4.905073179200281 %\n",
      "\n",
      "********** User_249 **********\n",
      "Filme_7\n",
      "Valor predito:  3.6054536482366113\n",
      "Valor real:  5.0\n",
      "Diferença:  27.890927035267776 %\n",
      "\n",
      "Filme_8\n",
      "Valor predito:  3.609030031296787\n",
      "Valor real:  4.0\n",
      "Diferença:  9.774249217580323 %\n",
      "\n",
      "Filme_64\n",
      "Valor predito:  4.624174051960101\n",
      "Valor real:  5.0\n",
      "Diferença:  7.516518960797979 %\n",
      "\n",
      "Filme_67\n",
      "Valor predito:  3.0578310967109066\n",
      "Valor real:  1.0\n",
      "Diferença:  -205.78310967109067 %\n",
      "\n",
      "********** User_104 **********\n",
      "Filme_2\n",
      "Valor predito:  3.4983446508649405\n",
      "Valor real:  3.0\n",
      "Diferença:  -16.611488362164685 %\n",
      "\n",
      "Filme_58\n",
      "Valor predito:  3.7797842044199226\n",
      "Valor real:  4.0\n",
      "Diferença:  5.505394889501936 %\n",
      "\n",
      "Filme_77\n",
      "Valor predito:  3.7298034168154706\n",
      "Valor real:  3.0\n",
      "Diferença:  -24.326780560515694 %\n",
      "\n",
      "Filme_79\n",
      "Valor predito:  3.913201429044314\n",
      "Valor real:  4.0\n",
      "Diferença:  2.1699642738921554 %\n",
      "\n",
      "********** User_289 **********\n",
      "Filme_8\n",
      "Valor predito:  3.5389890129073662\n",
      "Valor real:  4.0\n",
      "Diferença:  11.525274677315844 %\n",
      "\n",
      "Filme_50\n",
      "Valor predito:  3.6962887269226616\n",
      "Valor real:  5.0\n",
      "Diferença:  26.074225461546764 %\n",
      "\n",
      "Filme_56\n",
      "Valor predito:  3.4577145937335705\n",
      "Valor real:  3.0\n",
      "Diferença:  -15.25715312445235 %\n",
      "\n",
      "Filme_77\n",
      "Valor predito:  2.776526333811478\n",
      "Valor real:  5.0\n",
      "Diferença:  44.46947332377044 %\n",
      "\n",
      "********** User_212 **********\n",
      "Filme_2\n",
      "Valor predito:  2.8472479621038427\n",
      "Valor real:  3.0\n",
      "Diferença:  5.091734596538577 %\n",
      "\n",
      "Filme_13\n",
      "Valor predito:  3.573712780368528\n",
      "Valor real:  2.0\n",
      "Diferença:  -78.6856390184264 %\n",
      "\n",
      "Filme_28\n",
      "Valor predito:  3.3694708902075514\n",
      "Valor real:  3.0\n",
      "Diferença:  -12.315696340251714 %\n",
      "\n",
      "Filme_31\n",
      "Valor predito:  3.098404154906114\n",
      "Valor real:  3.0\n",
      "Diferença:  -3.280138496870477 %\n",
      "\n",
      "********** User_50 **********\n",
      "Filme_12\n",
      "Valor predito:  4.200793427616059\n",
      "Valor real:  4.0\n",
      "Diferença:  -5.019835690401475 %\n",
      "\n",
      "Filme_20\n",
      "Valor predito:  3.2941221382558012\n",
      "Valor real:  4.0\n",
      "Diferença:  17.64694654360497 %\n",
      "\n",
      "Filme_22\n",
      "Valor predito:  3.85169616365205\n",
      "Valor real:  5.0\n",
      "Diferença:  22.966076726958995 %\n",
      "\n",
      "Filme_32\n",
      "Valor predito:  3.630484446864896\n",
      "Valor real:  4.0\n",
      "Diferença:  9.237888828377605 %\n",
      "\n",
      "********** User_244 **********\n",
      "Filme_25\n",
      "Valor predito:  3.207350942754936\n",
      "Valor real:  4.0\n",
      "Diferença:  19.816226431126605 %\n",
      "\n",
      "Filme_56\n",
      "Valor predito:  4.1749521868161\n",
      "Valor real:  5.0\n",
      "Diferença:  16.500956263678003 %\n",
      "\n",
      "Filme_58\n",
      "Valor predito:  3.7943218747047074\n",
      "Valor real:  2.0\n",
      "Diferença:  -89.71609373523538 %\n",
      "\n",
      "Filme_64\n",
      "Valor predito:  4.321193300332768\n",
      "Valor real:  4.0\n",
      "Diferença:  -8.02983250831919 %\n",
      "\n",
      "********** User_240 **********\n",
      "Filme_5\n",
      "Valor predito:  3.4441667287947033\n",
      "Valor real:  4.0\n",
      "Diferença:  13.895831780132417 %\n",
      "\n",
      "Filme_51\n",
      "Valor predito:  3.2942635608423156\n",
      "Valor real:  3.0\n",
      "Diferença:  -9.808785361410521 %\n",
      "\n",
      "Filme_58\n",
      "Valor predito:  3.8716148463154267\n",
      "Valor real:  4.0\n",
      "Diferença:  3.2096288421143315 %\n",
      "\n",
      "Filme_66\n",
      "Valor predito:  3.5915984125011127\n",
      "Valor real:  5.0\n",
      "Diferença:  28.16803174997775 %\n",
      "\n",
      "********** User_164 **********\n",
      "Filme_33\n",
      "Valor predito:  2.4510422613760903\n",
      "Valor real:  1.0\n",
      "Diferença:  -145.10422613760903 %\n",
      "\n",
      "Filme_37\n",
      "Valor predito:  1.8579105988798403\n",
      "Valor real:  1.0\n",
      "Diferença:  -85.79105988798403 %\n",
      "\n",
      "Filme_53\n",
      "Valor predito:  2.249099521155935\n",
      "Valor real:  2.0\n",
      "Diferença:  -12.454976057796753 %\n",
      "\n",
      "Filme_60\n",
      "Valor predito:  2.6820111843759684\n",
      "Valor real:  1.0\n",
      "Diferença:  -168.20111843759685 %\n",
      "\n",
      "********** User_52 **********\n",
      "Filme_4\n",
      "Valor predito:  3.7534593141589854\n",
      "Valor real:  5.0\n",
      "Diferença:  24.93081371682029 %\n",
      "\n",
      "Filme_25\n",
      "Valor predito:  3.46783476953551\n",
      "Valor real:  4.0\n",
      "Diferença:  13.304130761612253 %\n",
      "\n",
      "Filme_28\n",
      "Valor predito:  3.98737476064224\n",
      "Valor real:  4.0\n",
      "Diferença:  0.31563098394400413 %\n",
      "\n",
      "Filme_64\n",
      "Valor predito:  4.917949761565924\n",
      "Valor real:  5.0\n",
      "Diferença:  1.64100476868152 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = np.random.randint(0, df_test.shape[0], size=11)\n",
    "\n",
    "for i in index:\n",
    "    print('*' * 10 + ' ' + df_test.index[i] + ' ' + '*' * 10)\n",
    "    condition = df_test.iloc[i, :] != 0\n",
    "\n",
    "    j = 0\n",
    "    for item in condition:\n",
    "\n",
    "        if item:\n",
    "            print(df_test.columns[j])\n",
    "            print('Valor predito: ', end= ' ')\n",
    "            print(df_pred_c.iloc[i, j], end='\\n')\n",
    "            print('Valor real: ', end= ' ')\n",
    "            print(df_test.iloc[i, j], end='\\n')\n",
    "            print('Diferença: ', end=' ')\n",
    "            print((1 - df_pred_c.iloc[i, j]/df_test.iloc[i, j]) * 100, end=' ')\n",
    "            print('%', end='\\n\\n')\n",
    "            j += 1\n",
    "        else:\n",
    "            j += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maior e menor diferença apresentada para o caso acima foi bastante similar ao anterior: 150% e 0.01%. Apesar da diminuição do MSE, o modelo escolhido é o baseado na média harmônica das MSE de treino e validação. Sendo assim, os valores dos parâmetros ideais são:\n",
    "\n",
    "- K = 10\n",
    "- $\\alpha$ = 0.0034\n",
    "- $\\beta$ = 0.11111\n",
    "\n",
    "onde o número de steps depende da convergência do valor de MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusões\n",
    "\n",
    "Os resultados discutidos ao longo deste notebook mostraram que a medida em que a MSE_train aumentava, a MSE_val diminuia. Com o intuito de minimizar a MSE em geral, foi escolhida como métrica a média harmônica entre MSE_train e MSE_val. Dessa maneira, obtivemos os valores de MSE para os dados de treino e validação que não representam nem o mínimo, nem o máximo de cada um deles, mas sim, a combinação que apresentou maior consistência do modelo.\n",
    "\n",
    "Para otimizar a escolha do modelo, foi adicionado um critério de parada para evitar cálculos desnecessários. Quando o MSE calculado para o valor atual for diferente em 0,1% ou menos do valor anterior, os cálculos são parados e são testados os próximos parâmetros, sendo assim, para cada parâmetro, o número de passo variou. Essas informações podem ser vistas nos dataframes \"df_resultados\" para cada um dos modelos.\n",
    "\n",
    "Com isso em mente, chegamos a dois modelos:\n",
    "\n",
    "__Primeiro caso:__ Quantidade de amostras retiradas por usuário: 2\n",
    "\n",
    "Parâmetros usados:\n",
    "\n",
    "- K = 10\n",
    "- $\\alpha$ = 0.0023\n",
    "- $\\beta$ = 0.2\n",
    "- numéro de passos: máximo = 5000\n",
    "\n",
    "__Segundo caso:__ Quantidade de amostras retiradas por usuário: 4\n",
    "\n",
    "Parâmetros usados:\n",
    "\n",
    "- K = 10\n",
    "- $\\alpha$ = 0.0034\n",
    "- $\\beta$ = 0.111111\n",
    "- numéro de passos: máximo = 5000\n",
    "\n",
    "A partir destes dois casos, vemos que o segundo  modelo se comporta melhor, mesmo apresentando MSE superior. Isso ocorre, devido ao aumento do número de dados de validação e teste. Através da amostragem, vemos que o modelo se comporta melhor que os outros apresentados, uma vez que, para um mesmo usuário, a diferença máxima e mínima são, aproximadamente, da mesma grandeza. Sendo assim, o modelo escolhido para a recomendação é aquele que apresenta o ajusta considerando os parâmetros apresentados no __segundo caso__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
